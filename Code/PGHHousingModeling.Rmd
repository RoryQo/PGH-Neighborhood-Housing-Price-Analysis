---
title: "PGH Housing Prices Modeling"
author: "Rory Quinlan"
date: "2025-03-14"
output: html_document
---


```{r}
library(tidyverse)
library(car)
library(ggplot2)
library(MASS)
library(readxl)
library(softImpute)
library(stargazer)
library(gridExtra)
```


```{r}
# Read Data
df= read.csv("C:\\Users\\roryq\\Downloads\\MQE_Data\\pgh_dropped.csv", header=T, sep= ",")
colnames(df)
```
```{r}

```

```{r}
# Define the desired order of levels
rating_levels <- c("POOR", "POOR -", "POOR +", "BELOW AVERAGE", "BELOW AVERAGE -", 
                   "BELOW AVERAGE +", "AVERAGE", "AVERAGE -", "AVERAGE +", 
                   "GOOD", "GOOD -", "GOOD +", "VERY GOOD", "VERY GOOD -", 
                   "VERY GOOD +", "EXCELLENT", "EXCELLENT -", "EXCELLENT +", 
                   "Highest Cost", "Highest Cost -", "Highest Cost +")

# Encode the 'ratings' column as a factor with the specified levels
df$GRADEDESC <- factor(df$GRADEDESC, levels = rating_levels, ordered = TRUE)
# Convert the ordered factor to numeric values (ordinal encoding)
df$GRADEDESC <- as.numeric(df$GRADEDESC)




```

```{r, results='asis'}
stargazer(df, type='text')

unique(df$YEARBLT)

```


```{r}


# Drop rows with NA in a specific column
df <- subset(df, !is.na(GRADEDESC))

# Count the number of NAs in each column
colSums(is.na(df))
```

```{r}
# Calculate average price and standard error of the mean (SEM) for each ZIP code
zipcode_summary <- df %>%
  group_by(PROPERTYZIP.x) %>%
  summarise(
    avg_price = mean(PRICE, na.rm = TRUE),
    sem_price = sd(PRICE, na.rm = TRUE) / sqrt(n())  # Standard error of the mean
  )

# Reorder ZIP codes by average price from lowest to highest
zipcode_summary$PROPERTYZIP.x <- reorder(zipcode_summary$PROPERTYZIP.x, zipcode_summary$avg_price)


# Create a plot with error bars for the average price by ZIP code
p<- ggplot(zipcode_summary, aes(x = PROPERTYZIP.x, y = avg_price)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.7) +  # Bar plot
  geom_errorbar(aes(ymin = avg_price - sem_price, ymax = avg_price + sem_price), 
                width = 0.2, color = "red") +  # Error bars
  labs(title = "Average House Price by ZIP Code",
       x = "ZIP Code",
       y = "Average House Price") +  # Rotate X-axis labels for better readability
  theme_minimal()+
   theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

p
```
```{r,eval=F}


# Define the full model (max_model) and the null model (min_model)
max_model <- formula(lm(PRICE ~ LOTAREA + STYLE + STORIES + YEARBLT + EXTERIORFINISH + BASEMENT + GRADEDESC + CONDITION + TOTALROOMS + BEDROOMS + FULLBATHS + HALFBATHS + HEATINGCOOLING + FIREPLACES + BSMTGARAGE + FINISHEDLIVINGAREA + SALEYEAR + SALEDESC.x + CONDITION, data = df))

min_model <- lm(PRICE ~ 1, data = df)  # null model (intercept only)

best_model = step(min_model, direction = "both", scope = max_model)

# View best model
best_model
```
```{r, eval=F}
best_model
summary(best_model)

# Diagnostic plots for the linear regression model
par(mfrow = c(2, 2))  # Arrange the plots in a 2x2 grid
plot(best_model)
```


```{r}
# Load necessary libraries
library(car)        # For VIF and regression diagnostics
library(MASS)       # For robust regression
library(sandwich)   # For robust standard errors
library(lmtest)     # For hypothesis testing

# Load your data (assuming df is your dataset)
# df <- read.csv("your_data.csv") 

# 1. Log-transform PRICE to stabilize variance and improve normality
df$LOG_PRICE <- log(df$PRICE + 1)


df$FULLBATHS <- as.factor(df$FULLBATHS)
df$HALFBATHS <- as.factor(df$HALFBATHS)
df$BEDROOMS <- as.factor(df$BEDROOMS)
df$FIREPLACES <- as.factor(df$FIREPLACES)
df$STORIES <- as.factor(df$STORIES)
df$AGE <- df$SALEYEAR - df$YEARBLT  # Instead of logging YEARBLT

# 2. Fit the linear model with transformed response variable
model <- lm(LOG_PRICE ~ GRADEDESC + log(FINISHEDLIVINGAREA + 0.001) + SALEDESC.x + 
    HEATINGCOOLING + STYLE + FULLBATHS + log(LOTAREA + 0.001) + 
    HALFBATHS + CONDITION + FIREPLACES + log(TOTALROOMS + 0.001) + 
    EXTERIORFINISH + BEDROOMS + STORIES+ AGE, data = df)


# 3. Check for multicollinearity using VIF
vif_values <- vif(model)
print(vif_values)


# 4. Identify and remove influential points based on Cookâ€™s Distance
influence <- influence.measures(model)
high_influence <- which(influence$infmat[, "cook.d"] > 4/(nrow(df)-length(model$coefficients)-2))
df <- df[-high_influence, ]

# 5. Refit the model after removing influential points
model <- lm(LOG_PRICE ~ GRADEDESC + log(FINISHEDLIVINGAREA + 0.01) + SALEDESC.x + 
    HEATINGCOOLING + STYLE + FULLBATHS + log(LOTAREA + 0.01) + 
    HALFBATHS + CONDITION +FIREPLACES + log(TOTALROOMS + 0.01) + 
    EXTERIORFINISH + I(SALEYEAR - YEARBLT) + BEDROOMS + STORIES, data = df)


# 6. Check for heteroskedasticity using a Breusch-Pagan test
library(lmtest)
bptest(model)

# If heteroskedasticity is present, use robust standard errors
robust_se <- coeftest(model, vcov = vcovHC(model, type = "HC3"))
print(robust_se)


# 8. Check residual plots
par(mfrow=c(2,2))
plot(model)

# Save updated model summary
summary(model)

```
```{r}



```
```{r, result='asis'}
library(boot)

# Fit the model with all the predictors and including PROPERTYZIP.x as a factor
model <- lm(LOG_PRICE ~ GRADEDESC + log(FINISHEDLIVINGAREA + 0.01) + SALEDESC.x + 
            HEATINGCOOLING + STYLE + FULLBATHS + log(LOTAREA + 0.01) + 
            HALFBATHS + CONDITION + FIREPLACES + log(TOTALROOMS + 0.01) + 
            EXTERIORFINISH + I(SALEYEAR - YEARBLT) + BEDROOMS + STORIES + 
            as.factor(PROPERTYZIP.x)+ as.factor(SALEYEAR), data = df)

# Perform ANCOVA to compare the mean prices across different PROPERTYZIP.x levels
ancova_results <- aov(model)

# Display the ANCOVA table
summary(ancova_results)
```
```{r}
library(emmeans)
grid <- ref_grid(model, nuisance = c("GRADEDESC", "SALEDESC.x", "HEATINGCOOLING", "STYLE", 
                                     "FULLBATHS", "CONDITION", "FIREPLACES", "EXTERIORFINISH",
                                     "BEDROOMS", "STORIES", "YEARBLT"))
# Calculate the adjusted means for PROPERTYZIP.x, considering the nuisance factors
adjusted_means <- emmeans(grid, ~ PROPERTYZIP.x * SALEYEAR)

# Display the adjusted means
summary(adjusted_means)
```
```{r}

# Convert adjusted means back to the original scale (inverse of Box-Cox transformation)
adjusted_means_df <- as.data.frame(adjusted_means)

```
```{r}

```
```{r}
model_wls <- lm(LOG_PRICE ~ GRADEDESC + log(FINISHEDLIVINGAREA + 0.01) + SALEDESC.x + 
                HEATINGCOOLING + STYLE + FULLBATHS + log(LOTAREA + 0.01) + 
                HALFBATHS + CONDITION + FIREPLACES + log(TOTALROOMS + 0.01) + 
                EXTERIORFINISH + I(SALEYEAR - YEARBLT) + BEDROOMS + STORIES + 
                as.factor(PROPERTYZIP.x), data = df, weights = 1 / sqrt(fitted(model)))

grid <- ref_grid(model_wls, nuisance = c("GRADEDESC", "SALEDESC.x", "HEATINGCOOLING", "STYLE", 
                                     "FULLBATHS", "CONDITION", "FIREPLACES", "EXTERIORFINISH",
                                     "BEDROOMS", "STORIES", "SALEYEAR", "YEARBLT"))
# Calculate the adjusted means for PROPERTYZIP.x, considering the nuisance factors
adjusted_means <- emmeans(grid, ~ PROPERTYZIP.x)

adjusted_means_df<- as.data.frame(adjusted_means)

# Order the zip codes by adjusted mean price
adjusted_means_df$PROPERTYZIP.x <- reorder(adjusted_means_df$PROPERTYZIP.x, adjusted_means_df$adjusted_price)

# Find the lowest mean price and its corresponding upper confidence interval
lowest_mean_price <- min(adjusted_means_df$adjusted_price)
lowest_upper_ci <- adjusted_means_df$upper_ci[which.min(adjusted_means_df$adjusted_price)]


# Create a barplot with error bars, ordered by mean price
wp<- ggplot(adjusted_means_df, aes(x = PROPERTYZIP.x, y = adjusted_price)) +
  geom_bar(stat = "identity", fill = "skyblue", width = 0.7) +  # Bar plot for adjusted price
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) + 
  geom_hline(yintercept = lowest_upper_ci, color = "red", linetype = "dashed", size = 1) +# Error bars
  labs(x = "Property Zip Code", y = "Adjusted Mean Price", title = "Adjusted Mean Prices by Zip Code (Ordered & Weighted)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
wp

# 8. Check residual plots
par(mfrow=c(2,2))
plot(model_wls)

# Save updated model summary
summary(model_wls)

```

```{r}
# Apply Box-Cox transformation to the model
boxcox_model <- boxCox(model, plotit = TRUE)

# View the lambda (optimal transformation)
boxcox_model

```
```{r}
# Transform PRICE based on Box-Cox lambda
df$PRICE_transformed <- df$PRICE^.5

# Fit the model with the transformed dependent variable
model_transformed <- lm(PRICE_transformed ~ GRADEDESC + log(FINISHEDLIVINGAREA + 0.01) + 
                        SALEDESC.x + HEATINGCOOLING + STYLE + FULLBATHS + 
                        log(LOTAREA + 0.01) + HALFBATHS + CONDITION + 
                        FIREPLACES + log(TOTALROOMS + 0.01) + EXTERIORFINISH + 
                        I(SALEYEAR - YEARBLT) + BEDROOMS + STORIES + 
                        as.factor(PROPERTYZIP.x)+ as.factor(SALEYEAR), data = df)

par(mfrow=c(2,2))
plot(model_transformed)
```
```{r}

grid <- ref_grid(model_transformed, nuisance = c("GRADEDESC", "SALEDESC.x", "HEATINGCOOLING", "STYLE", 
                                     "FULLBATHS", "CONDITION", "FIREPLACES", "EXTERIORFINISH",
                                     "BEDROOMS", "STORIES", "YEARBLT"))

adjusted_means_transformed <- emmeans(grid, ~ PROPERTYZIP.x * SALEYEAR)

# Convert adjusted means back to the original scale (inverse of the power transformation)
adjusted_means_df <- as.data.frame(adjusted_means_transformed)
adjusted_means_df$adjusted_price <- adjusted_means_df$emmean^2  # Inverse of square root transformation (i.e., square the adjusted means)

# Calculate the confidence intervals for adjusted prices
adjusted_means_df$lower_ci <- adjusted_means_df$lower.CL^2  # Lower bound transformed back
adjusted_means_df$upper_ci <- adjusted_means_df$upper.CL^2  # Upper bound transformed back

# Order the adjusted means by adjusted price (from lowest to highest)
adjusted_means_df$PROPERTYZIP.x <- reorder(adjusted_means_df$PROPERTYZIP.x, adjusted_means_df$adjusted_price)

# Plot the adjusted means with error bars
library(ggplot2)
pp<-ggplot(adjusted_means_df, aes(x = PROPERTYZIP.x, y = adjusted_price)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.7) +  # Bar plot for adjusted price
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2, color = "black") +  # Error bars
  labs(title = "Adjusted House Price by ZIP Code (Transformed to Original Scale)",
       x = "Property Zip Code",
       y = "Adjusted House Price (Original Scale)") +
  # Rotate X-axis labels for better readability
  theme_minimal()+
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

pp
```

```{r}

```
```{r}
# Sort the data frame by adjusted means to find the top and bottom 3 zip codes
top_3_zipcodes <- adjusted_means_df %>%
  arrange(desc(emmean)) %>%
  head(3) %>%
  pull(PROPERTYZIP.x)

bottom_3_zipcodes <- adjusted_means_df %>%
  arrange(emmean) %>%
  head(3) %>%
  pull(PROPERTYZIP.x)

# Filter the data to include only these 6 zip codes
filtered_data <- adjusted_means_df %>%
  filter(PROPERTYZIP.x %in% c(top_3_zipcodes, bottom_3_zipcodes))
```

```{r}
ggplot(filtered_data, aes(x = SALEYEAR, y = adjusted_price, color = PROPERTYZIP.x, group = PROPERTYZIP.x)) +
  geom_line(size = 1) +  # Line plot for each ZIP code
  geom_point(size = 3) +  # Points for each year per ZIP code
  geom_errorbar(aes(ymin = lower.CL^2, ymax = upper.CL^2), width = 0.2) +  # Error bars (converted to original scale)
  labs(title = "Adjusted Housing Prices Over Time by ZIP Code",
       x = "Year",
       y = "Adjusted Average Housing Price",
       color = "ZIP Code") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

```

```{r}
adjusted_means_transformed <- emmeans(grid, ~ PROPERTYZIP.x * SALEYEAR)

# Step 3: Convert adjusted means back to the original scale (inverse of square root transformation)
adjusted_means_df <- as.data.frame(adjusted_means_transformed)
adjusted_means_df$adjusted_price <- adjusted_means_df$emmean^2  # Inverse of square root transformation

# Step 4: Find the 3 most expensive and 3 least expensive ZIP codes based on adjusted mean price
avg_price_by_zip <- adjusted_means_df %>%
  group_by(PROPERTYZIP.x) %>%
  summarise(avg_price = mean(adjusted_price, na.rm = TRUE))

# Get top 3 and bottom 3 zip codes
top_3_zipcodes <- avg_price_by_zip %>%
  arrange(desc(avg_price)) %>%
  head(3) %>%
  pull(PROPERTYZIP.x)

bottom_3_zipcodes <- avg_price_by_zip %>%
  arrange(avg_price) %>%
  head(3) %>%
  pull(PROPERTYZIP.x)

# Step 5: Filter data to include only the top and bottom 3 zip codes
filtered_data <- adjusted_means_df %>%
  filter(PROPERTYZIP.x %in% c(top_3_zipcodes, bottom_3_zipcodes))

# Step 6: Create the line graph with ggplot2 (one point per year)
ggplot(filtered_data, aes(x = SALEYEAR, y = adjusted_price, color = PROPERTYZIP.x, group = PROPERTYZIP.x)) +
  geom_line(size = 1) +  # Line plot for each ZIP code
  geom_point(size = 3) +  # Points for each year per ZIP code
  geom_errorbar(aes(ymin = lower.CL^2, ymax = upper.CL^2), width = 0.2) +  # Error bars (converted to original scale)
  labs(title = "Adjusted Housing Prices Over Time by ZIP Code",
       x = "Year",
       y = "Adjusted Average Housing Price",
       color = "ZIP Code") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```
```{r}
library(scales)

# Ensure that PROPERTYZIP.x is treated as a factor for discrete color scale
filtered_data$PROPERTYZIP.x <- factor(filtered_data$PROPERTYZIP.x)

# Step 6: Create the line graph with ggplot2 (one point per year for each ZIP code)
ggplot(filtered_data, aes(x = SALEYEAR, y = adjusted_price, color = PROPERTYZIP.x, group = PROPERTYZIP.x)) +
  geom_line(size = 1) +  # Line plot for each ZIP code
  geom_point(size = 3) +  # Points for each year per ZIP code
  geom_errorbar(aes(ymin = lower.CL^2, ymax = upper.CL^2), width = 0.2) +  # Error bars (converted to original scale)
  labs(title = "Adjusted Housing Prices Over Time by ZIP Code",
       x = "Year",
       y = "Adjusted Average Housing Price",
       color = "ZIP Code") +
  scale_color_manual(values = c( "#1f77b4",  # Dark Blue
    "#9edae5",  # Light Blue
    "#2ca02c",  # Teal
    "#aec7e8",  # Lighter Blue
    "#7f7f7f",  # Grayish Blue
    "#B9AEDC" )) +  # Use distinct colors for each ZIP code
  scale_y_continuous(labels = label_number(scale = 1)) +  # Remove scientific notation on Y-axis
  scale_x_continuous(labels = label_comma()) +
   scale_x_continuous(labels = waiver())+# Format x-axis (if necessary)
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability
        legend.title = element_text(size = 12),  # Adjust legend title size
        legend.text = element_text(size = 10))  # Adjust legend text size
```
```{r}
# Step 1: Calculate the difference between PRICE and FAIRMARKETTOTAL
df$DIFFERENCE <- df$PRICE - df$FAIRMARKETTOTAL

# Step 2: Group by ZIP code and calculate the average difference and standard error
zipcode_difference_summary <- df %>%
  group_by(PROPERTYZIP.x) %>%
  summarise(
    avg_difference = mean(DIFFERENCE, na.rm = TRUE),
    sem_difference = sd(DIFFERENCE, na.rm = TRUE) / sqrt(n())  # Standard error of the mean
  )

# Step 3: Reorder ZIP codes by average difference from lowest to highest
zipcode_difference_summary$PROPERTYZIP.x <- reorder(zipcode_difference_summary$PROPERTYZIP.x, zipcode_difference_summary$avg_difference)

# Step 4: Create a bar plot with error bars for the average difference by ZIP code
ggplot(zipcode_difference_summary, aes(x = PROPERTYZIP.x, y = avg_difference)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.7) +  # Bar plot
  geom_errorbar(aes(ymin = avg_difference - sem_difference, ymax = avg_difference + sem_difference), 
                width = 0.2, color = "red") +  # Error bars
  labs(title = "Average Difference Between PRICE and FAIRMARKETTOTAL by ZIP Code",
       x = "ZIP Code",
       y = "Average Difference (PRICE - FAIRMARKETTOTAL)") +  # Y-axis label
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X-axis labels for better readability

```
```{r}
# Step 2: Calculate the average price for each ZIP code (to identify the most and least expensive ones)
zipcode_avg_price <- df %>%
  group_by(PROPERTYZIP.x) %>%
  summarise(
    avg_price = mean(PRICE, na.rm = TRUE)
  )

# Step 3: Identify the top 3 most expensive and top 3 least expensive ZIP codes
top_3_zipcodes <- zipcode_avg_price %>%
  arrange(desc(avg_price)) %>%
  head(3) %>%
  pull(PROPERTYZIP.x)

bottom_3_zipcodes <- zipcode_avg_price %>%
  arrange(avg_price) %>%
  head(3) %>%
  pull(PROPERTYZIP.x)

# Step 4: Filter the data to include only the top 3 and bottom 3 zip codes
filtered_data <- df %>%
  filter(PROPERTYZIP.x %in% c(top_3_zipcodes, bottom_3_zipcodes))

# Step 5: Group by SALEYEAR and PROPERTYZIP.x, then calculate the average difference for each group
zipcode_year_summary <- filtered_data %>%
  group_by(SALEYEAR, PROPERTYZIP.x) %>%
  summarise(
    avg_difference = mean(DIFFERENCE, na.rm = TRUE)
  )

# Step 6: Ensure PROPERTYZIP.x is treated as a factor to use as lines in the plot
zipcode_year_summary$PROPERTYZIP.x <- factor(zipcode_year_summary$PROPERTYZIP.x)

# Step 7: Create the line graph with ggplot2
ggplot(zipcode_year_summary, aes(x = SALEYEAR, y = avg_difference, color = PROPERTYZIP.x, group = PROPERTYZIP.x)) +
  geom_line(size = 1) +  # Line plot for each ZIP code
  geom_point(size = 3) +  # Points for each year per ZIP code
  labs(title = "Average Difference (PRICE - FAIRMARKETTOTAL) Over Time by ZIP Code",
       x = "Year",
       y = "Average Difference (PRICE - FAIRMARKETTOTAL)",
       color = "ZIP Code") +
  scale_y_continuous(labels = scales::label_number()) +  # Remove scientific notation on Y-axis
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```
```{r}
write.csv(adjusted_means_df, file = "C:\\Users\\roryq\\Downloads\\MQE_Data\\ADJPrice_Trans_time.csv", row.names = FALSE)
```

```{r, results='asis'}
library(stargazer)
stargazer(model, type='text')
```
```{r}
# Load necessary libraries
library(rstan)

# Define your model in Stan
stan_model_code <- "
data {
  int<lower=0> N;  // Number of observations
  vector[N] price; // Response variable (house prices)
  matrix[N, K] X;  // Matrix of predictor variables (ZIP code, GRADEDESC, etc.)
}

parameters {
  real alpha;       // Intercept
  vector[K] beta;   // Coefficients for predictors
  real<lower=0> sigma;  // Error term
}

model {
  // Weakly informative priors
  alpha ~ normal(0, 10);  // Prior for intercept
  beta ~ normal(0, 5);    // Prior for coefficients
  sigma ~ cauchy(0, 5);   // Prior for error term

  price ~ normal(alpha + X * beta, sigma);  // Likelihood
}

generated quantities {
  real price_pred[N];
  for (n in 1:N)
    price_pred[n] = normal_rng(alpha + dot_product(X[n], beta), sigma);  // Predicted values
}
"

# Prepare your data
data_list <- list(
  N = nrow(df),  # Number of observations
  price = sqrt(df$PRICE),  # Square root transformed response variable (PRICE)
  X = cbind(1, df$GRADEDESC, 
            log(df$FINISHEDLIVINGAREA + 0.01), 
            df$SALEDESC.x, 
            df$HEATINGCOOLING, 
            df$STYLE, 
            df$FULLBATHS, 
            log(df$LOTAREA + 0.01), 
            df$HALFBATHS, 
            df$CONDITION, 
            df$FIREPLACES, 
            log(df$TOTALROOMS + 0.01), 
            df$EXTERIORFINISH, 
            df$SALEYEAR - df$YEARBLT, 
            df$BEDROOMS, 
            df$STORIES)  # Add more predictors as necessary
)

# Fit the model using MCMC sampling
fit <- stan(model_code = stan_model_code, data = data_list, iter = 2000, chains = 4)

# View the results
print(fit)

# Extract posterior samples
posterior_samples <- extract(fit)

# Calculate 95% credible intervals for the coefficients
posterior_summary <- summary(fit)$summary
beta_credible_intervals <- posterior_summary[grep("beta", rownames(posterior_summary)), c("2.5%", "97.5%")]

# Print the credible intervals for the ZIP code coefficients
print(beta_credible_intervals)

# Plot the posterior distributions of ZIP code coefficients
plot(fit, pars = c("beta"))

```

